{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":97926,"databundleVersionId":11667523,"sourceType":"competition"}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport nltk\nimport os\nfrom nltk.corpus import stopwords\nimport string\nimport re\nfrom nltk.tokenize import word_tokenize\nimport pymorphy2\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nnltk.download('stopwords')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T09:49:18.367711Z","iopub.execute_input":"2025-04-10T09:49:18.368069Z","iopub.status.idle":"2025-04-10T09:49:18.523852Z","shell.execute_reply.started":"2025-04-10T09:49:18.368038Z","shell.execute_reply":"2025-04-10T09:49:18.522974Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Unzipping corpora/stopwords.zip.\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"**Импорт библиотек**","metadata":{}},{"cell_type":"code","source":"stopwords = nltk.corpus.stopwords.words('russian')\nmorph = pymorphy2.MorphAnalyzer()\nwn = nltk.WordNetLemmatizer()\ndef remove_punctuation(text):\n    text = str(text)\n    return ''.join([ch for ch in text if ch not in\n    string.punctuation])\n\ndef remove_numbers(text):\n    return ''.join([i if not i.isdigit() else ' ' for i in text])\n\ndef remove_notalpha(text):\n    return ''.join(i if i.isalpha() else ' ' for i in text)\n\n\ndef remove_space(text):\n    return re.sub(r'\\s+',' ', text, flags=re.I)\n\n\ndef tokenize(text):\n    t = word_tokenize(text)\n    return [token for token in t if token not in stopwords]\n\n\ndef lemmatize(text):\n    res = list()\n    for word in text:\n        p = morph.parse(word)[0]\n        res.append(p.normal_form)\n    return res","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T09:49:23.627976Z","iopub.execute_input":"2025-04-10T09:49:23.628358Z","iopub.status.idle":"2025-04-10T09:49:24.166856Z","shell.execute_reply.started":"2025-04-10T09:49:23.628325Z","shell.execute_reply":"2025-04-10T09:49:24.165960Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"**Функции для обработки текста**","metadata":{}},{"cell_type":"code","source":"def textProcessing(df):\n    text_list = []\n    for i in df['title']:\n        if i is not None:\n            i = remove_punctuation(i)\n            i = remove_numbers(i)\n            i = remove_notalpha(i)\n            i = remove_space(i)\n            i = tokenize(i)\n            i = lemmatize(i)\n            text_list.append(i)\n    return text_list\n\n\ndef urlProcessing(df):\n    url_list = []\n    keywords = {\n        \"porn\", \"sex\", \"adult\", \"video\", \"cam\", \"cum\", \"blowjob\", \"xxx\", \"x\", \"ero\", \"anal\"\n        \"boobs\", \"onlyfans\", \"hub\", \"model\", \"fap\", \"girl\", \"lesbian\", \"hot\", \"horny\", \"teen\", \n        \"milf\", \"asian\", \"hd\", \"pussy\", \"dick\", \"fuck\", \"nude\", \"couple\"\n    }\n    for url in df['url']:\n        found_keywords = []\n        if isinstance(url, str):\n            url_lower = url.lower()\n            for kw in keywords:\n                if kw in url_lower:\n                    found_keywords.append(kw)\n        url_list.append(\" \".join(found_keywords))\n    return url_list","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T09:50:15.809584Z","iopub.execute_input":"2025-04-10T09:50:15.809947Z","iopub.status.idle":"2025-04-10T09:50:15.817239Z","shell.execute_reply.started":"2025-04-10T09:50:15.809908Z","shell.execute_reply":"2025-04-10T09:50:15.816097Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"**Обработка текста и url**","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/ml-2025-spring-porn-detection/train.csv\", encoding='utf-8')\ntest_df = pd.read_csv(\"/kaggle/input/ml-2025-spring-porn-detection/test.csv\", encoding='utf-8')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T09:50:39.629078Z","iopub.execute_input":"2025-04-10T09:50:39.629454Z","iopub.status.idle":"2025-04-10T09:50:41.398166Z","shell.execute_reply.started":"2025-04-10T09:50:39.629423Z","shell.execute_reply":"2025-04-10T09:50:41.397009Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"**Загрузка данных**","metadata":{}},{"cell_type":"code","source":"def formFeautures(text_list, url_list):\n    X = []\n    for text, url in zip(text_list, url_list):\n        X.append(str(text) + \" \" + str(url))\n    return X\ndef trainModel(X, y):\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n    \n    model = Pipeline([\n        ('tfidf', TfidfVectorizer(max_features=5000, ngram_range=(1, 1))),\n        ('logreg', LogisticRegression(solver='saga', max_iter=1000, C=10))\n    ])\n    \n    \n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    print(\"\\nРезультат на тестовых данных:\")\n    print(classification_report(y_test, y_pred))\n    \n    return model\ntext_list, url_list = textProcessing(df), urlProcessing(df)\nX = formFeautures(text_list, url_list)\ny = df['label']\nmodel = trainModel(X, y)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T10:29:30.708898Z","iopub.execute_input":"2025-04-10T10:29:30.709274Z","iopub.status.idle":"2025-04-10T10:33:14.636107Z","shell.execute_reply.started":"2025-04-10T10:29:30.709241Z","shell.execute_reply":"2025-04-10T10:33:14.634936Z"}},"outputs":[{"name":"stdout","text":"\nРезультат на тестовых данных:\n              precision    recall  f1-score   support\n\n           0       0.99      1.00      1.00     35582\n           1       0.99      0.95      0.97      5011\n\n    accuracy                           0.99     40593\n   macro avg       0.99      0.97      0.98     40593\nweighted avg       0.99      0.99      0.99     40593\n\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"**Формирование признаков и обучение модели**","metadata":{}},{"cell_type":"code","source":"test_text_list, test_url_list = textProcessing(test_df), urlProcessing(test_df)\ntest_X = formFeautures(test_text_list, test_url_list)\ny_predict = model.predict(test_X)\nresult_df = pd.DataFrame({'ID': test_df['ID'],\n                          'label': y_predict})\nresult_df.to_csv('submission.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T10:12:17.398059Z","iopub.execute_input":"2025-04-10T10:12:17.398437Z","iopub.status.idle":"2025-04-10T10:16:47.519840Z","shell.execute_reply.started":"2025-04-10T10:12:17.398410Z","shell.execute_reply":"2025-04-10T10:16:47.518744Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"**Создание submission файла**","metadata":{}}]}